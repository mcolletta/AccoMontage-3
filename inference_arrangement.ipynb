{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead Sheet to Multi-Track Arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lead sheet to piano arrangement module (piano arranger). This may take 1 or 2 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 18.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading piano to multi-track arrangement module (orchestrator). This may take 1 or 2 minutes ...\n",
      "loading Slakh2100 Dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331/331 [00:02<00:00, 129.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing prior model\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import pretty_midi as pyd\n",
    "from arrangement_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"Download checkpoints and data at https://drive.google.com/file/d/1ZyswS0p_t2Ij5vyaFkM5IbVgphf78oTB/view?usp=sharing and decompress at the directory\"\"\"\n",
    "DATA_FILE_ROOT = './data_file_dir/' #configure this dir to where you've saved and decompressed the zip\n",
    "DEVICE = 'cuda:0'\n",
    "piano_arranger, orchestrator, piano_texture, band_prompt = load_premise(DATA_FILE_ROOT, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize input\n",
    "We provide a few sample lead sheets for a quick inference. You can run the code blocks after downloading the pre-trained checkpoints.\n",
    "\n",
    "If you wish to test our model on your own lead sheet file, please initialize a sub-folder with its `SONG_NAME` in the `./demo` folder and put the file in, and name the file \"lead sheet.mid\". \n",
    "\n",
    "Please also specify `SEGMENTATION` (phrase structure) and `NOTE_SHIFT` (the number of pick-up beats if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set input lead sheet\"\"\"\n",
    "SONG_NAME, SEGMENTATION, NOTE_SHIFT, TEMPO = '01 Can You Feel The Love Tonight', 'i4A8B8B8x4A8B8B8O4', 0, 65\n",
    "#SONG_NAME, SEGMENTATION, NOTE_SHIFT, TEMPO = '02 All I Want For Christmas Is You', 'A16B11C2A16B11C2D16E6C2O8', 0, 140\n",
    "#SONG_NAME, SEGMENTATION, NOTE_SHIFT, TEMPO = '03 Boogie woogie bugle boy', 'A12A12B12', 4, 120\n",
    "#SONG_NAME, SEGMENTATION, NOTE_SHIFT, TEMPO = '04 Castles in the Air', 'A8A8B8B8', 1 , 100  #1 beat in the pick-up measure\n",
    "#SONG_NAME, SEGMENTATION, NOTE_SHIFT, TEMPO = '05 Jingle Bells', 'A8B8A8', 0, 100\n",
    "#SONG_NAME, SEGMENTATION, NOTE_SHIFT, TEMPO = '06 Sally Garden', 'A4A4B4A4', 0, 75\n",
    "\n",
    "lead_sheet = read_lead_sheet('./demo', SONG_NAME, SEGMENTATION, NOTE_SHIFT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piano Accompaniment Arrangement\n",
    "\n",
    "Stage 1: piano accompaniment arrangement from lead sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set texture prefilter for piano arranger\"\"\"\n",
    "RHTHM_DENSITY = 2   #np.random.randint(2, 5)\n",
    "VOICE_NUMBER = 3    #np.random.randint(2, 5)\n",
    "PREFILTER = (RHTHM_DENSITY, VOICE_NUMBER)\n",
    "\n",
    "midi_piano, acc_piano = piano_arrangement(*lead_sheet, *piano_texture, piano_arranger, PREFILTER, TEMPO)\n",
    "midi_path = f'./demo/{SONG_NAME}/arrangement_piano.mid'\n",
    "midi_piano.write(midi_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestration\n",
    "\n",
    "Stage 2: multi-track orchestration from piano\n",
    "\n",
    "We need to decide using what instruments for orchestration. Here, we sample a piece from Slakh2100 dataset and borrow its instruments.\n",
    "\n",
    "You can choose which instruments you wish to have or not by passing thier program number to the `MUST_HAVE` or `MUSTNOT_HAVE` list. We support 34 instrument classes as listed [here](orchestrator/autoencoder_dataset.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUST_HAVE = [0, 24] # 0: Acoustic Piano;24: Acoustic Guitar;\n",
    "MUSTNOT_HAVE = [64] # 64: Soprano/Alto Sax\n",
    "func_prompt = prompt_sampling(acc_piano, *band_prompt, MUST_HAVE, MUSTNOT_HAVE, DEVICE)\n",
    "\n",
    "\"\"\"Set if use a 2-bar orchestral prompt for full-band arrangement (default True)\"\"\" \n",
    "USE_PROMPT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we orchestrate the piano arrangement from Stage 1 to a multi-track arrangement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PROMPT:\n",
    "    instruments, time_promt = func_prompt\n",
    "else:\n",
    "    instruments, _ = func_prompt\n",
    "    time_promt = None\n",
    "midi_collection = orchestration(acc_piano, None, instruments, time_promt, orchestrator, DEVICE, blur=.25, p=.05, t=6, tempo=TEMPO, num_sample=4)\n",
    "\n",
    "mel_track = pyd.Instrument(program=82, is_drum=False, name='melody')\n",
    "mel_track.notes = midi_piano.instruments[0].notes\n",
    "for idx, piece in enumerate(midi_collection):\n",
    "    piece.instruments = [mel_track] + piece.instruments\n",
    "    midi_path = f'./demo/{SONG_NAME}/arrangement_band-{str(idx).zfill(2)}.mid'\n",
    "    piece.write(midi_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.10_conda11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
