{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading piano to multi-track arrangement module (orchestrator). This may take 1 or 2 minutes ...\n",
      "loading Slakh2100 Dataset ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331/331 [00:02<00:00, 125.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing prior model\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import pretty_midi as pyd\n",
    "from midi2audio import FluidSynth\n",
    "import IPython.display as ipd\n",
    "from arrangement_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"Download checkpoints and data at https://drive.google.com/drive/folders/17yB-Oae_4eGKJmqRS-LB8PwE2rqwZrUu?usp=sharing (455MB) and decompress at the directory\"\"\"\n",
    "DATA_FILE_ROOT = '/data1/zhaojw/data_file_dir/'\n",
    "DEVICE = 'cuda:0'\n",
    "_, orchestrator, _, band_prompt = load_premise(DATA_FILE_ROOT, DEVICE, load_piano_arranger=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize input and preference\n",
    "We provide four sample piano arrangements for a quick inference. You should be able to directly run the code blocks after downloading the pre-trained checkpoints.\n",
    "\n",
    "If you wish to test our model on your own lead sheet file, please initialize a sub-folder with its `SONG_NAME` in the `./demo` folder and put the file in, and name the file \"arrangement_piano.mid\". \n",
    "\n",
    "Please also specify `NOTE_SHIFT` (the number of pick-up beats if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SONG_NAME, NOTE_SHIFT, TEMPO = '07 The Moon Represents My Heart', 1.5, 70\n",
    "#SONG_NAME, NOTE_SHIFT, TEMPO = '08 Suddenly Miss You So Bad', 22, 80\n",
    "#SONG_NAME, NOTE_SHIFT, TEMPO = '09 I Only Care About You',18.5, 80\n",
    "SONG_NAME, NOTE_SHIFT, TEMPO = '10 Floral Sea', 0, 75\n",
    "\n",
    "\n",
    "melody, pno_red = read_piano_reduction('./demo', SONG_NAME, NOTE_SHIFT, melody_track_ID=0)\n",
    "pno_red = pno_red.reshape((-1, 32, 128))\n",
    "\n",
    "\"\"\"have a quick listen to the lead sheet\"\"\"\n",
    "midi_path = f'./demo/{SONG_NAME}/arrangement_piano.mid'\n",
    "audio_path = midi_path.replace('.mid', '.wav')\n",
    "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(midi_path, audio_path)\n",
    "ipd.Audio(audio_path, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestration\n",
    "\n",
    "Stage 2: multi-track orchestration from piano\n",
    "\n",
    "Firstly we're going to sample a piece from Slakh2100 dataset and utilize its instrument set for orchestration. \n",
    "\n",
    "You can choose which instruments you wish to have or not by passing thier program number to the `MUST_HAVE` or `MUSTNOT_HAVE` list. We support 34 instrument classes as shown [here](orchestrator/autoencoder_dataset.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior model initialized with 10 tracks:\n",
      "\t['Organ', 'Pipe', 'Electric Piano', 'Choir and Voice', 'Clean Electric Guitar', 'Choir and Voice', 'Acoustic Guitar', 'Electric Bass', 'Clean Electric Guitar', 'Distorted Electric Guitar']\n"
     ]
    }
   ],
   "source": [
    "MUST_HAVE = []\n",
    "MUSTNOT_HAVE = [0] # 0: Acoustic Piano\n",
    "func_prompt = prompt_sampling(pno_red, *band_prompt, MUSTNOT_HAVE=MUSTNOT_HAVE, DEVICE=DEVICE)\n",
    "\n",
    "\"\"\"Set if use a 2-bar orchestral prompt for full-band arrangement (default True)\"\"\" \n",
    "USE_PROMPT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we orchestrate the piano arrangement from Stage 1 to a multi-track arrangement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PROMPT = True\n",
    "if USE_PROMPT:\n",
    "    instruments, time_promt = func_prompt\n",
    "else:\n",
    "    instruments, _ = func_prompt\n",
    "    time_promt = None\n",
    "midi_collection = orchestration(pno_red, None, instruments, time_promt, orchestrator, DEVICE, blur=.25, p=.05, t=6, tempo=TEMPO, num_sample=4)\n",
    "\n",
    "melody_track = matrix2midi(melody[np.newaxis, :, :], [82], init_tempo=TEMPO)\n",
    "for idx, item in enumerate(midi_collection):\n",
    "    item.instruments.append(melody_track.instruments[0])\n",
    "    midi_path = f'./demo/{SONG_NAME}/arrangement_band-{str(idx).zfill(2)}.mid'\n",
    "    item.write(midi_path)\n",
    "\n",
    "\"\"\"have a quick listen to (one of) the orchestration results\"\"\"\n",
    "audio_path = midi_path.replace('.mid', '.wav')\n",
    "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(midi_path, audio_path)\n",
    "ipd.Audio(audio_path, rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.10_conda11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
